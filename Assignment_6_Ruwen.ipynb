{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94bde72f-afa0-4c5a-9e0e-05a4397575c7",
   "metadata": {},
   "source": [
    "# Assignment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6176cb0-8914-47e0-9361-273b3d3a0b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1b0666a0b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from heapq import nlargest\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import os\n",
    "import evaluate\n",
    "from transformers import pipeline\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d372d0b-6605-4690-8f23-23b8aeccd548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruwen/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/ruwen/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "labels2id = {\"anger\": 0, \"joy\": 1, \"optimism\": 2, \"sadness\": 3}\n",
    "id2labels = {0: \"anger\", 1: \"joy\", 2: \"optimism\", 3: \"sadness\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf5cd639-17f8-463a-a8f1-1fc272416774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lines: 3257\n",
      "Training labels: 3257\n",
      "Validation lines: 374\n",
      "Validation labels: 374\n",
      "Test lines: 1421\n",
      "Test labels: 1421\n"
     ]
    }
   ],
   "source": [
    "with open('/home/ruwen/tweeteval/datasets/emotion/train_text.txt') as f:\n",
    "    t_lines = f.read().splitlines()\n",
    "\n",
    "with open('/home/ruwen/tweeteval/datasets/emotion/test_text.txt') as f:\n",
    "    test_lines = f.read().splitlines()\n",
    "\n",
    "with open('/home/ruwen/tweeteval/datasets/emotion/val_text.txt') as f:\n",
    "    val_lines = f.read().splitlines()\n",
    "\n",
    "with open('/home/ruwen/tweeteval/datasets/emotion/train_labels.txt') as f:\n",
    "    train_labels = f.read().splitlines()\n",
    "\n",
    "train_labels = [int(numeric_string) for numeric_string in train_labels]\n",
    "\n",
    "with open('/home/ruwen/tweeteval/datasets/emotion/test_labels.txt') as f:\n",
    "    test_labels = f.read().splitlines()\n",
    "\n",
    "test_labels = [int(numeric_string) for numeric_string in test_labels]\n",
    "\n",
    "with open('/home/ruwen/tweeteval/datasets/emotion/val_labels.txt') as f:\n",
    "    val_labels = f.read().splitlines()\n",
    "\n",
    "val_labels = [int(numeric_string) for numeric_string in val_labels]\n",
    "\n",
    "\n",
    "print(\"Training lines: \" + str(len(t_lines)))\n",
    "print(\"Training labels: \" + str(len(train_labels)))\n",
    "print(\"Validation lines: \" + str(len(val_lines)))\n",
    "print(\"Validation labels: \" + str(len(val_labels)))\n",
    "print(\"Test lines: \" + str(len(test_lines)))\n",
    "print(\"Test labels: \" + str(len(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1039b806-68c7-4cc6-b53d-09af57b0dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = []\n",
    "test_dict = []\n",
    "val_dict = []\n",
    "\n",
    "for i,l in enumerate(t_lines):\n",
    "    train_dict.append({\"text\": l, \"label\": train_labels[i]})\n",
    "\n",
    "for i,l in enumerate(test_lines):\n",
    "    test_dict.append({\"text\": l, \"label\": test_labels[i]})\n",
    "\n",
    "for i,l in enumerate(val_lines):\n",
    "    val_dict.append({\"text\": l, \"label\": val_labels[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "055f90ad-79de-4321-bf91-8f57c14527fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19fae107-b045-48b2-9913-08b02a581930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df013e6fbccd4a6c823c639e18bc6570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3257 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acea06f53894c568e32c7cf1236cf25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/374 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585916ceb0ac468fbd5f3600a7a75b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets = DatasetDict()\n",
    "tweets[\"train\"] = Dataset.from_list(train_dict)\n",
    "tweets[\"val\"] = Dataset.from_list(val_dict)\n",
    "tweets[\"test\"] = Dataset.from_list(test_dict)\n",
    "\n",
    "tweets_tokens = tweets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c071e5-2df9-48f7-8b38-84b31fdf9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a980d559-81c3-4f47-bf39-ba84b15c8842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=4, id2label=id2labels, label2id=labels2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd85fe63-8163-4d8c-966c-2b0d4b180cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf40884-cd4b-4321-91e4-74c94bd61e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='816' max='816' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [816/816 30:54, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.640598</td>\n",
       "      <td>0.780749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.661333</td>\n",
       "      <td>0.780749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.446100</td>\n",
       "      <td>0.718129</td>\n",
       "      <td>0.775401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.446100</td>\n",
       "      <td>0.721432</td>\n",
       "      <td>0.786096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tweets_tokens[\"train\"],\n",
    "    eval_dataset=tweets_tokens[\"val\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "trainer.train()\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc46168a-7994-4219-bbe2-e9eab2896976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"./my_awesome_model/checkpoint-408\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"./my_awesome_model/checkpoint-408\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for entry in test_dict:\n",
    "            inputs = tokenizer(entry[\"text\"], return_tensors=\"pt\")\n",
    "            logits = model(**inputs).logits\n",
    "                \n",
    "            predicted_class_id = logits.argmax().item()\n",
    "            model.config.id2label[predicted_class_id]\n",
    "            \n",
    "            correct += (predicted_class_id == entry[\"label\"])\n",
    "            total += 1\n",
    "    \n",
    "    print(f'Accuracy of the network on the test data: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03dc06e3-185b-4f05-a3e8-1dc98752e044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test data: 80 %\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f8a3012-1d09-4f72-93f3-16d53404d0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0:30:56.849409\n"
     ]
    }
   ],
   "source": [
    "print(\"time: \" + str(datetime.timedelta(seconds=(end - start))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5defdb-7026-4940-b90b-ff11a2c3d811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
